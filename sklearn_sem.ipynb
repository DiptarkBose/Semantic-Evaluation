{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def preprocess(f_name):\n",
    "    f=open(f_name, 'r')\n",
    "    txt1=f.read().translate(str.maketrans(\"\\t\\r\", \"  \"))\n",
    "    txt1 = txt1.lower()\n",
    "    \"\".join(txt1.split())\n",
    "    txt=txt1.split('\\n')\n",
    "    sentence_corpora=[]\n",
    "    sentence_labels=[]\n",
    "    words=[]\n",
    "    for i in range(0, 31984, 4):\n",
    "        txt[i]=txt[i].lstrip('0123456789')\n",
    "        txt[i]=txt[i].replace('\\\"','')\n",
    "        txt[i]=txt[i].replace('.','')\n",
    "        at=str(txt[i].strip())\n",
    "        for elem in at.split(\" \"):\n",
    "            words.append(elem.replace(\"<e1>\",\"\").replace(\"</e1>\", \"\").replace(\"</e2>\", \"\").replace(\"<e2>\", \"\"))\n",
    "        sentence_corpora.append(str(txt[i].strip().replace(\"<e1>\",\"\").replace(\"</e1>\", \"\").replace(\"</e2>\", \"\").replace(\"<e2>\", \"\")))\n",
    "        sentence_labels.append(str(txt[i+1].strip().replace(\"(e1,e2)\", \"\").replace(\"(e2,e1)\", \"\")))\n",
    "    return sentence_corpora,sentence_labels,words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['the system as described above has its greatest application in an arrayed configuration of antenna elements', 'the child was carefully wrapped and bound into the cradle by means of a cord', 'the author of a keygen uses a disassembler to look at the raw assembly code', 'a misty ridge uprises from the surge', 'the student association is the voice of the undergraduate student population of the state university of new york at buffalohello sir', \"this is the sprawling complex that is peru's largest producer of silver\", 'the current view is that the chronic inflammation in the distal part of the stomach caused by helicobacter pylori infection results in an increased acid production from the non-infected upper corpus region of the stomach', 'people have been moving back into downtown', 'the lawsonite was contained in a platinum crucible and the counter-weight was a plastic crucible with metal pieces', 'the solute was placed inside a beaker and 5 ml of the solvent was pipetted into a 25 ml glass flask for each trial']\n"
     ]
    }
   ],
   "source": [
    "sentence_corpora,sentence_labels,words = preprocess(\"TRAIN_FILE.TXT\")\n",
    "print(type(sentence_corpora))\n",
    "print(sentence_corpora[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22947\n"
     ]
    }
   ],
   "source": [
    "#Setting Label values for Softmax Classifier\n",
    "label_dict={\"cause-effect\": 0, \n",
    "            \"instrument-agency\": 1, \n",
    "            \"product-producer\": 2, \n",
    "            \"content-container\": 3, \n",
    "            \"entity-origin\": 4, \n",
    "            \"entity-destination\": 5, \n",
    "            \"component-whole\": 6,\n",
    "            \"member-collection\": 7,\n",
    "            \"message-topic\": 8,\n",
    "            \"other\": 9}\n",
    "final_labels=[]\n",
    "for elem in sentence_labels:\n",
    "    final_labels.append(label_dict[elem])\n",
    "final_labels = np.array(final_labels)\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab,0)}\n",
    "print(len(vocab_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[6 9 1 9 7 9 0 5 3 5]\n"
     ]
    }
   ],
   "source": [
    "print(type(final_labels))\n",
    "print(final_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train,x_test,y_train,y_test = train_test_split(sentence_corpora,final_labels,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7996, 19145)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(sentence_corpora)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7996, 19145)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 17240)\t0.051541530138\n",
      "  (0, 16937)\t0.227632272502\n",
      "  (0, 1394)\t0.150007682703\n",
      "  (0, 5004)\t0.28761472774\n",
      "  (0, 484)\t0.275084166443\n",
      "  (0, 8043)\t0.14980173258\n",
      "  (0, 9252)\t0.196402966198\n",
      "  (0, 7738)\t0.302849288377\n",
      "  (0, 1222)\t0.314926013731\n",
      "  (0, 8728)\t0.0900431528313\n",
      "  (0, 1032)\t0.142641658696\n",
      "  (0, 1354)\t0.390143029606\n",
      "  (0, 3933)\t0.344023927474\n",
      "  (0, 11850)\t0.0726551862258\n",
      "  (0, 1131)\t0.31857870051\n",
      "  (0, 5855)\t0.327002739085\n",
      "  (1, 17240)\t0.117531085922\n",
      "  (1, 11850)\t0.0828384694061\n",
      "  (1, 3279)\t0.313639706809\n",
      "  (1, 18621)\t0.135334659458\n",
      "  (1, 2921)\t0.359065750277\n",
      "  (1, 19001)\t0.367792245539\n",
      "  (1, 1059)\t0.0998160665467\n",
      "  (1, 2393)\t0.392242000488\n",
      "  (1, 9108)\t0.151053783916\n",
      "  :\t:\n",
      "  (2, 1491)\t0.176145183206\n",
      "  (2, 13965)\t0.345528048496\n",
      "  (2, 1428)\t0.331406521897\n",
      "  (2, 3591)\t0.323105319889\n",
      "  (3, 17240)\t0.067087255579\n",
      "  (3, 11004)\t0.507816222558\n",
      "  (3, 14599)\t0.507816222558\n",
      "  (3, 18152)\t0.469941926415\n",
      "  (3, 7182)\t0.151764530787\n",
      "  (3, 16775)\t0.485661179573\n",
      "  (4, 17240)\t0.177101329046\n",
      "  (4, 11850)\t0.187237311468\n",
      "  (4, 1491)\t0.139511086911\n",
      "  (4, 16548)\t0.457922887158\n",
      "  (4, 1460)\t0.260154342181\n",
      "  (4, 9211)\t0.0964856320673\n",
      "  (4, 18496)\t0.295524282148\n",
      "  (4, 17984)\t0.302099027445\n",
      "  (4, 13105)\t0.242646317981\n",
      "  (4, 16311)\t0.217650556396\n",
      "  (4, 18056)\t0.229923134205\n",
      "  (4, 11554)\t0.170358142571\n",
      "  (4, 19084)\t0.247067512352\n",
      "  (4, 2604)\t0.335141626938\n",
      "  (4, 15692)\t0.295524282148\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_tfidf))\n",
    "print(X_train_tfidf[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('TEST_FILE_FULL.TXT', 'r')\n",
    "txt1=f.read().translate(str.maketrans(\"\\t\\r\", \"  \"))\n",
    "txt1 = txt1.lower()\n",
    "\"\".join(txt1.split())\n",
    "txt=txt1.split('\\n')\n",
    "sentence_test=[]\n",
    "labels_test=[]\n",
    "words=[]\n",
    "for i in range(0, 10866, 4):\n",
    "    txt[i]=txt[i].lstrip('0123456789')\n",
    "    txt[i]=txt[i].replace('\\\"','')\n",
    "    txt[i]=txt[i].replace('.','')\n",
    "    at=str(txt[i].strip())\n",
    "    for elem in at.split(\" \"):\n",
    "        words.append(elem.replace(\"<e1>\",\"\").replace(\"</e1>\", \"\").replace(\"</e2>\", \"\").replace(\"<e2>\", \"\"))\n",
    "    sentence_test.append(str(txt[i].strip().replace(\"<e1>\",\"\").replace(\"</e1>\", \"\").replace(\"</e2>\", \"\").replace(\"<e2>\", \"\")))\n",
    "    labels_test.append(str(txt[i+1].strip().replace(\"(e1,e2)\", \"\").replace(\"(e2,e1)\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_labels_test=[]\n",
    "for elem in labels_test:\n",
    "    final_labels_test.append(label_dict[elem])\n",
    "final_labels_test = np.array(final_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', MultinomialNB(alpha=0.01)),\n",
    "])\n",
    "text_clf = text_clf.fit(sentence_corpora, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58667648141332351"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(sentence_test)\n",
    "np.mean(predicted == final_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3,1e-3),\n",
    "              'vect__stop_words':('english',None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3f8784c2a3ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgs_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_corpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_clf' is not defined"
     ]
    }
   ],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(sentence_corpora, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01,\n",
       " 'tfidf__use_idf': False,\n",
       " 'vect__ngram_range': (1, 2),\n",
       " 'vect__stop_words': None}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6205373573794627"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf-svm', SGDClassifier(loss='squared_hinge', penalty='l2',\n",
    "                                           alpha=2*1e-4, n_iter=800, random_state=100,learning_rate='constant',eta0=0.0009)),\n",
    " ])\n",
    "_ = text_clf_svm.fit(sentence_corpora, final_labels)\n",
    "predicted_svm = text_clf_svm.predict(sentence_test)\n",
    "np.mean(predicted_svm == final_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content-container\n"
     ]
    }
   ],
   "source": [
    "f2 = open('new_file.txt','w')\n",
    "pred = text_clf_svm.predict(['There is water in the bucket'])\n",
    "for label, val in label_dict.items():\n",
    "    if val == pred:\n",
    "        print(label)\n",
    "        f2.write(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
